{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "system requirements\n",
    "1. activate gedi env, cuda 11.7\n",
    "2. install tinycudann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch.nn.functional as F\n",
    "from gedi import GeDi\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import os\n",
    "\n",
    "from models.fields import FeatureField\n",
    "from pyhocon import ConfigFactory\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"script for extract DINO feature from rendered image and geometric features from pointcloud, visualizing feature matching results\n",
    "\"\"\"\n",
    "def sample_point_cloud_from_mesh(mesh_path, number_of_points=100000,save_to_file=True):\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "    \n",
    "    # Check if the mesh has vertex normals, if not, compute them\n",
    "    if not mesh.has_vertex_normals():\n",
    "        mesh.compute_vertex_normals()\n",
    "    \n",
    "    # Sample points uniformly from the mesh\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=number_of_points)\n",
    "\n",
    "    if save_to_file:\n",
    "        pcd_fname = mesh_path.replace(\"glb\",\"pcd\")\n",
    "        if not os.path.exists(pcd_fname):\n",
    "            print(f'cache extracted pcd file to {pcd_fname}')\n",
    "            o3d.io.write_point_cloud(pcd_fname, pcd)\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def load_pointcloud(pcd_fname):\n",
    "    if os.path.exists(pcd_fname):\n",
    "        print(f\"read cached pcd file from {pcd_fname}\")\n",
    "        pcd = o3d.io.read_point_cloud(pcd_fname)\n",
    "    else:\n",
    "        print(\"can't find cached pcd file, read from mesh file\")\n",
    "        mesh_path = pcd_fname.replace(\"pcd\",\"glb\")\n",
    "        pcd = sample_point_cloud_from_mesh(mesh_path)\n",
    "    return pcd\n",
    "\n",
    "def visualize_point_cloud(pcd):\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_fname):\n",
    "    # read network config\n",
    "    conf_path = './confs/wmask.conf'\n",
    "    f = open(conf_path)\n",
    "    conf_text = f.read()\n",
    "    conf_text = conf_text.replace('CASE_NAME', 'owl') #TODO case name as input\n",
    "    f.close()\n",
    "    conf = ConfigFactory.parse_string(conf_text)\n",
    "\n",
    "    # load feature field\n",
    "    checkpoint = torch.load(os.path.join(checkpoint_fname), map_location='cuda')\n",
    "    feature_network = FeatureField(**conf['model.feature_field']).to('cuda')\n",
    "    # self.nerf_outside.load_state_dict(checkpoint['nerf'])\n",
    "    # self.sdf_network.load_state_dict(checkpoint['sdf_network_fine'])\n",
    "    # self.deviation_network.load_state_dict(checkpoint['variance_network_fine'])\n",
    "    # self.color_network.load_state_dict(checkpoint['color_network_fine'])\n",
    "    feature_network.load_state_dict(checkpoint['feature_network'])\n",
    "    # self.optimizer_geometry.load_state_dict(checkpoint['optimizer-geometry'])\n",
    "    # self.optimizer_feature.load_state_dict(checkpoint['optimizer-feature'])\n",
    "\n",
    "    # iter_step = checkpoint['iter_step']\n",
    "    print(f\"loaded checkpoint from {checkpoint_fname}\")\n",
    "    return feature_network\n",
    "\n",
    "\n",
    "def visualize_point_cloud(pcd):\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geo_feature(pcd=None, config=None):\n",
    "    if config == None:\n",
    "        config = {\n",
    "          'dim': 32,                                            # descriptor output dimension\n",
    "          'samples_per_batch': 500,                             # batches to process the data on GPU\n",
    "          'samples_per_patch_lrf': 4000,                        # num. of point to process with LRF\n",
    "          'samples_per_patch_out': 512,                         # num. of points to sample for pointnet++\n",
    "          'r_lrf': .5,                                          # LRF radius\n",
    "          'fchkpt_gedi_net': 'data/chkpts/3dmatch/chkpt.tar',   # path to checkpoint\n",
    "          'device':'cpu',\n",
    "        }  \n",
    "    voxel_size = .01\n",
    "    patches_per_pair = 5000\n",
    "\n",
    "    # initialising class\n",
    "    gedi = GeDi(config=config)\n",
    "\n",
    "    # getting a pair of point clouds\n",
    "    if pcd==None: # if not passing pcd directly, read from local storage\n",
    "        pcd0 = o3d.io.read_point_cloud('data/assets/threed_match_7-scenes-redkitchen_cloud_bin_0.ply')\n",
    "    else:\n",
    "        pcd0 = pcd\n",
    "\n",
    "    pcd0.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "    # estimating normals (only for visualisation)\n",
    "    pcd0.estimate_normals()\n",
    "\n",
    "    # randomly sampling some points from the point cloud\n",
    "    inds0 = np.random.choice(np.asarray(pcd0.points).shape[0], patches_per_pair, replace=False) # 5000\n",
    "\n",
    "    pts0 = torch.tensor(np.asarray(pcd0.points)[inds0]).float() # 5000 x 3 \n",
    "\n",
    "    # applying voxelisation to the point cloud\n",
    "    pcd0 = pcd0.voxel_down_sample(voxel_size)\n",
    "\n",
    "    # pcd in tensor\n",
    "    _pcd0 = torch.tensor(np.asarray(pcd0.points)).float()\n",
    "\n",
    "    # computing descriptors\n",
    "    pcd0_desc = gedi.compute(pts=pts0, pcd=_pcd0) # 5000x32\n",
    "\n",
    "    return pcd0_desc, pts0\n",
    "\n",
    "# is scale kept consist from MESH to pcd then goes back? are geometry feature point and dino feature point the same point?\n",
    "def extract_DINO_feature_from_model(model_ckpt, pts):\n",
    "    model = load_checkpoint(model_ckpt)\n",
    "    return model(pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here setup the case name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "casename1 = 'cup1'\n",
    "casename2 = 'cup2'\n",
    "iteration = '3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read cached pcd file from ./exp/neus/cup1/meshes/cup1_3000.pcd\n",
      "loaded checkpoint from ./exp/neus/cup1/checkpoints/ckpt_003000.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pcd_path_source = \"./exp/neus/mixer/meshes/mixer_5000.pcd\" \n",
    "pcd_path_source1 = f\"./exp/neus/{casename1}/meshes/{casename1}_{iteration}.pcd\"\n",
    "pcd_source1= load_pointcloud(pcd_path_source1)\n",
    "geo_features1, sampled_pts1 = extract_geo_feature(pcd_source1) # tensor on cpu, bc some operation dosen't support cuda\n",
    "\n",
    "# move tensor to GPU \n",
    "geo_features1 = geo_features1.to(device)\n",
    "sampled_pts1 = sampled_pts1.to(device)\n",
    "\n",
    "# extract DINO feature\n",
    "ckpt = f'./exp/neus/{casename1}/checkpoints/ckpt_00{iteration}.pth'\n",
    "DINO_features1 = extract_DINO_feature_from_model(ckpt,sampled_pts1)\n",
    "\n",
    "features1 = torch.cat((geo_features1,DINO_features1),1) # combined feature\n",
    "# features = DINO_features # DINO only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read cached pcd file from ./exp/neus/cup2/meshes/cup2_3000.pcd\n",
      "loaded checkpoint from ./exp/neus/cup2/checkpoints/ckpt_005000.pth\n"
     ]
    }
   ],
   "source": [
    "# extract features from second pointcloud\n",
    "# pcd_path_source2 = \"./exp/neus/owl/meshes/owl.pcd\" \n",
    "pcd_path_source2 = f\"./exp/neus/{casename2}/meshes/{casename2}_{iteration}.pcd\"\n",
    "\n",
    "pcd_source2= load_pointcloud(pcd_path_source2)\n",
    "geo_features2, sampled_pts2 = extract_geo_feature(pcd_source2) # tensor on cpu, bc some operation dosen't support cuda\n",
    "\n",
    "# move tensor to GPU \n",
    "geo_features2 = geo_features2.to(device)\n",
    "sampled_pts2 = sampled_pts2.to(device)\n",
    "\n",
    "# extract DINO feature\n",
    "ckpt = f'./exp/neus/{casename2}/checkpoints/ckpt_005000.pth'\n",
    "DINO_features2 = extract_DINO_feature_from_model(ckpt,sampled_pts2)\n",
    "\n",
    "features2 = torch.cat((geo_features2,DINO_features2),1) # combine features\n",
    "# features2 = DINO_features2 # DINO only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 2: (features1[6], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 3: (features1[4], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 4: (features1[5], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 5: (features1[1], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 6: (features1[0], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 7: (features1[2], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 8: (features1[3], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 9: (features1[8], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Pair 10: (features1[9], features2[4674]), Cosine Similarity: 0.629497230052948\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 2: (features1[6], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 3: (features1[4], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 4: (features1[5], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 5: (features1[1], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 6: (features1[0], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 7: (features1[2], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 8: (features1[3], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 9: (features1[8], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Pair 10: (features1[9], features2[2529]), Cosine Similarity: 0.7816359996795654\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 2: (features1[6], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 3: (features1[4], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 4: (features1[5], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 5: (features1[1], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 6: (features1[0], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 7: (features1[2], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 8: (features1[3], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 9: (features1[8], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Pair 10: (features1[9], features2[2529]), Cosine Similarity: 0.8256640434265137\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 2: (features1[6], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 3: (features1[4], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 4: (features1[5], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 5: (features1[1], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 6: (features1[0], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 7: (features1[2], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 8: (features1[3], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 9: (features1[8], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Pair 10: (features1[9], features2[2841]), Cosine Similarity: 0.7411285638809204\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 2: (features1[6], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 3: (features1[4], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 4: (features1[5], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 5: (features1[1], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 6: (features1[0], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 7: (features1[2], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 8: (features1[3], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 9: (features1[8], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Pair 10: (features1[9], features2[2387]), Cosine Similarity: 0.6838868260383606\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 2: (features1[6], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 3: (features1[4], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 4: (features1[5], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 5: (features1[1], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 6: (features1[0], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 7: (features1[2], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 8: (features1[3], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 9: (features1[8], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Pair 10: (features1[9], features2[2529]), Cosine Similarity: 0.8151769042015076\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 2: (features1[6], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 3: (features1[4], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 4: (features1[5], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 5: (features1[1], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 6: (features1[0], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 7: (features1[2], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 8: (features1[3], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 9: (features1[8], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Pair 10: (features1[9], features2[1741]), Cosine Similarity: 0.7527937889099121\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 2: (features1[6], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 3: (features1[4], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 4: (features1[5], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 5: (features1[1], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 6: (features1[0], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 7: (features1[2], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 8: (features1[3], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 9: (features1[8], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Pair 10: (features1[9], features2[2719]), Cosine Similarity: 0.6435256600379944\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 2: (features1[6], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 3: (features1[4], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 4: (features1[5], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 5: (features1[1], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 6: (features1[0], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 7: (features1[2], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 8: (features1[3], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 9: (features1[8], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Pair 10: (features1[9], features2[2537]), Cosine Similarity: 0.7453192472457886\n",
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 2: (features1[6], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 3: (features1[4], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 4: (features1[5], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 5: (features1[1], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 6: (features1[0], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 7: (features1[2], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 8: (features1[3], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 9: (features1[8], features2[23]), Cosine Similarity: 0.7948881387710571\n",
      "Pair 10: (features1[9], features2[23]), Cosine Similarity: 0.7948881387710571\n"
     ]
    }
   ],
   "source": [
    "# target_indxs = [np.random.randint(0,len(sampled_pts1))  for i in range(10)] # randomly choose some pts for finding corresponding\n",
    "\n",
    "# indx_1 = []\n",
    "# indx_2 = []\n",
    "# for ind in target_indxs:\n",
    "#     target_pt1 = sampled_pts1[ind]\n",
    "#     target_feature1 = features1[ind].reshape(1,-1)\n",
    "\n",
    "#     features1_tmp = target_feature1.repeat(features2.shape[0],1) # generate bunch \n",
    "\n",
    "#     # Normalize the features to get cosine similarity\n",
    "#     features1_norm = F.normalize(features1_tmp, p=2, dim=1)\n",
    "#     features2_norm = F.normalize(features2, p=2, dim=1)\n",
    "\n",
    "#     # Compute cosine similarity between all pairs\n",
    "#     cosine_sim = torch.mm(features1_norm, features2_norm.t())\n",
    "\n",
    "#     # Flatten the cosine similarity matrix and get the top similarity indices\n",
    "#     num_rank = 10\n",
    "#     cosine_sim_flat = cosine_sim.view(-1)\n",
    "#     topk_values, topk_indices = torch.topk(cosine_sim_flat, num_rank, largest=True)\n",
    "\n",
    "#     # Manually convert flat indices to 2D indices\n",
    "#     n_rows = cosine_sim.size(0)\n",
    "#     topk_indices_2d = [(idx // n_rows, idx % n_rows) for idx in topk_indices]\n",
    "\n",
    "#     print(\"Top 10 closest pairs (indices and cosine similarities):\")\n",
    "#     for i in range(num_rank):\n",
    "#         idx1, idx2 = topk_indices_2d[i]\n",
    "#         print(f\"Pair {i+1}: (features1[{idx1}], features2[{idx2}]), Cosine Similarity: {topk_values[i].item()}\")\n",
    "#         indx_1.append(ind)\n",
    "#         indx_2.append(idx2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of rows with maximum dot product: tensor([2580, 1126], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.7148, 0.7148], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([4659, 2276], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.7245, 0.7203], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([2790, 3438], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.7562, 0.7541], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([3489, 4938], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.8135, 0.8119], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([4242,  701], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.8018, 0.7987], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([ 585, 4371], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.5321, 0.5275], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([1131, 1754], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.7290, 0.7228], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([4775,  596], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.4534, 0.4360], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([2732, 4847], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.6400, 0.6395], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Indices of rows with maximum dot product: tensor([4572, 2867], device='cuda:0')\n",
      "Maximum dot product values: tensor([0.6970, 0.6879], device='cuda:0', grad_fn=<IndexBackward>)\n"
     ]
    }
   ],
   "source": [
    "target_indxs = [np.random.randint(0,len(sampled_pts1))  for i in range(10)] # randomly choose some pts for finding corresponding\n",
    "\n",
    "indx_1 = []\n",
    "indx_2 = []\n",
    "num_rank = 2\n",
    "for ind in target_indxs:\n",
    "\n",
    "    features1_tmp = features1[ind]\n",
    "    # # Normalize the features to get cosine similarity\n",
    "    features1_norm = F.normalize(features1_tmp, p=2, dim=0)\n",
    "    features2_norm = F.normalize(features2, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity between all pairs\n",
    "    cosine_sim = torch.matmul(features2_norm, features1_norm.t())\n",
    "\n",
    "    # # Flatten the cosine similarity matrix and get the top similarity indice\n",
    "    topk_values, topk_indices = torch.topk(cosine_sim, num_rank, largest=True)\n",
    "\n",
    "    # Get the rows with the maximum dot product values\n",
    "    max_rows = features2_norm[topk_indices]\n",
    "\n",
    "    # If you need the values as well\n",
    "    max_values = cosine_sim[topk_indices]\n",
    "\n",
    "    print(\"Indices of rows with maximum dot product:\", topk_indices)\n",
    "    # print(\"Rows with maximum dot product:\", max_rows)\n",
    "    print(\"Maximum dot product values:\", max_values)\n",
    "    indx_1.append(ind)\n",
    "    indx_2.append(topk_indices[0])\n",
    "    indx_1.append(ind)\n",
    "    indx_2.append(topk_indices[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a new point cloud to hold the combined points for visualization\n",
    "combined_points = np.vstack((sampled_pts1.cpu(), sampled_pts2.cpu()+1.0)) # some offset\n",
    "combined_pcd = o3d.geometry.PointCloud()\n",
    "combined_pcd.points = o3d.utility.Vector3dVector(combined_points)\n",
    "\n",
    "# Extract the corresponding points for the top pairs\n",
    "top_pairs_pts1 = np.array([sampled_pts1[idx].cpu().numpy() for idx in indx_1])\n",
    "top_pairs_pts2 = np.array([sampled_pts2[idx].cpu().numpy()+1.0 for idx in indx_2]) # compensate for the offset\n",
    "\n",
    "# Create lines connecting the top pairs\n",
    "# lines = [[idx1.cpu().numpy(), (idx2 + len(sampled_pts)).cpu().numpy()] for idx1, idx2 in topk_indices_2d]\n",
    "lines = [[i, i + len(top_pairs_pts1)] for i in range(len(top_pairs_pts1))]\n",
    "\n",
    "# Visualize point clouds with lines between top pairs\n",
    "colors = [[0, 0, 1] for _ in range(len(lines))]  # Blue lines\n",
    "\n",
    "line_set = o3d.geometry.LineSet()\n",
    "line_set.points = o3d.utility.Vector3dVector(np.vstack((top_pairs_pts1, top_pairs_pts2)))\n",
    "line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "spheres = []\n",
    "radius = 0.02  # Set the radius for the spheres\n",
    "for pt in np.vstack((top_pairs_pts1, top_pairs_pts2)):\n",
    "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius)\n",
    "    sphere.translate(pt)\n",
    "    sphere.paint_uniform_color([1, 0, 0])  # Color the spheres red\n",
    "    spheres.append(sphere)\n",
    "\n",
    "# Visualize the point clouds and the lines\n",
    "o3d.visualization.draw_geometries([combined_pcd, line_set] + spheres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### past results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000 to 5000 code\n",
    "# Normalize the features to get cosine similarity\n",
    "features1_norm = F.normalize(features1, p=2, dim=1)\n",
    "features2_norm = F.normalize(features2, p=2, dim=1)\n",
    "\n",
    "# Compute cosine similarity between all pairs\n",
    "cosine_sim = torch.mm(features1_norm, features2_norm.t())\n",
    "\n",
    "# Flatten the cosine similarity matrix and get the top 10 indices\n",
    "num_rank = 3\n",
    "cosine_sim_flat = cosine_sim.view(-1)\n",
    "topk_values, topk_indices = torch.topk(cosine_sim_flat, num_rank, largest=True)\n",
    "\n",
    "# Manually convert flat indices to 2D indices\n",
    "n_rows = cosine_sim.size(0)\n",
    "topk_indices_2d = [(idx // n_rows, idx % n_rows) for idx in topk_indices]\n",
    "\n",
    "print(\"Top 10 closest pairs (indices and cosine similarities):\")\n",
    "for i in range(num_rank):\n",
    "    idx1, idx2 = topk_indices_2d[i]\n",
    "    print(f\"Pair {i+1}: (features1[{idx1}], features2[{idx2}]), Cosine Similarity: {topk_values[i].item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gedi_o3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
