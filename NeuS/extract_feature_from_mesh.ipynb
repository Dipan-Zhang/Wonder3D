{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "system requirements\n",
    "1. activate gedi env, cuda 11.7\n",
    "2. install tinycudann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the following device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch.nn.functional as F\n",
    "from gedi import GeDi\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import os\n",
    "\n",
    "from models.fields import FeatureField\n",
    "from pyhocon import ConfigFactory\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('You are using the following device: ', device)\n",
    "\n",
    "\"\"\"script for extract DINO feature from rendered image and geometric features from pointcloud, visualizing feature matching results\n",
    "\"\"\"\n",
    "def sample_point_cloud_from_mesh(mesh_path, number_of_points=100000,save_to_file=True):\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "    \n",
    "    # Check if the mesh has vertex normals, if not, compute them\n",
    "    if not mesh.has_vertex_normals():\n",
    "        mesh.compute_vertex_normals()\n",
    "    \n",
    "    # Sample points uniformly from the mesh\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=number_of_points)\n",
    "\n",
    "    if save_to_file:\n",
    "        pcd_fname = mesh_path.replace(\"glb\",\"pcd\")\n",
    "        if not os.path.exists(pcd_fname):\n",
    "            print(f'cache extracted pcd file to {pcd_fname}')\n",
    "            o3d.io.write_point_cloud(pcd_fname, pcd)\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def load_pointcloud(pcd_fname):\n",
    "    if os.path.exists(pcd_fname):\n",
    "        print(f\"read cached pcd file from {pcd_fname}\")\n",
    "        pcd = o3d.io.read_point_cloud(pcd_fname)\n",
    "    else:\n",
    "        print(\"can't find cached pcd file, read from mesh file\")\n",
    "        mesh_path = pcd_fname.replace(\"pcd\",\"glb\")\n",
    "        pcd = sample_point_cloud_from_mesh(mesh_path)\n",
    "    return pcd\n",
    "\n",
    "def visualize_point_cloud(pcd):\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_fname):\n",
    "    # read network config\n",
    "    conf_path = './confs/wmask.conf'\n",
    "    f = open(conf_path)\n",
    "    conf_text = f.read()\n",
    "    conf_text = conf_text.replace('CASE_NAME', 'owl') #TODO case name as input\n",
    "    f.close()\n",
    "    conf = ConfigFactory.parse_string(conf_text)\n",
    "\n",
    "    # load feature field\n",
    "    checkpoint = torch.load(os.path.join(checkpoint_fname), map_location='cuda')\n",
    "    feature_network = FeatureField(**conf['model.feature_field']).to('cuda')\n",
    "    # self.nerf_outside.load_state_dict(checkpoint['nerf'])\n",
    "    # self.sdf_network.load_state_dict(checkpoint['sdf_network_fine'])\n",
    "    # self.deviation_network.load_state_dict(checkpoint['variance_network_fine'])\n",
    "    # self.color_network.load_state_dict(checkpoint['color_network_fine'])\n",
    "    feature_network.load_state_dict(checkpoint['feature_network'])\n",
    "    # self.optimizer_geometry.load_state_dict(checkpoint['optimizer-geometry'])\n",
    "    # self.optimizer_feature.load_state_dict(checkpoint['optimizer-feature'])\n",
    "\n",
    "    # iter_step = checkpoint['iter_step']\n",
    "    print(f\"loaded checkpoint from {checkpoint_fname}\")\n",
    "    return feature_network\n",
    "\n",
    "\n",
    "def visualize_point_cloud(pcd):\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geo_feature(pcd=None, config=None):\n",
    "    if config == None:\n",
    "        config = {\n",
    "          'dim': 32,                                            # descriptor output dimension\n",
    "          'samples_per_batch': 500,                             # batches to process the data on GPU\n",
    "          'samples_per_patch_lrf': 4000,                        # num. of point to process with LRF\n",
    "          'samples_per_patch_out': 512,                         # num. of points to sample for pointnet++\n",
    "          'r_lrf': .5,                                          # LRF radius\n",
    "          'fchkpt_gedi_net': 'data/chkpts/3dmatch/chkpt.tar',   # path to checkpoint\n",
    "          'device':'cpu',\n",
    "        }  \n",
    "    voxel_size = .01\n",
    "    patches_per_pair = 5000\n",
    "\n",
    "    # initialising class\n",
    "    gedi = GeDi(config=config)\n",
    "\n",
    "    # getting a pair of point clouds\n",
    "    if pcd==None: # if not passing pcd directly, read from local storage\n",
    "        pcd0 = o3d.io.read_point_cloud('data/assets/threed_match_7-scenes-redkitchen_cloud_bin_0.ply')\n",
    "    else:\n",
    "        pcd0 = pcd\n",
    "\n",
    "    pcd0.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "    # estimating normals (only for visualisation)\n",
    "    pcd0.estimate_normals()\n",
    "\n",
    "    # randomly sampling some points from the point cloud\n",
    "    inds0 = np.random.choice(np.asarray(pcd0.points).shape[0], patches_per_pair, replace=False) # 5000\n",
    "\n",
    "    pts0 = torch.tensor(np.asarray(pcd0.points)[inds0]).float() # 5000 x 3 \n",
    "\n",
    "    # applying voxelisation to the point cloud\n",
    "    pcd0 = pcd0.voxel_down_sample(voxel_size)\n",
    "\n",
    "    # pcd in tensor\n",
    "    _pcd0 = torch.tensor(np.asarray(pcd0.points)).float()\n",
    "\n",
    "    # computing descriptors\n",
    "    pcd0_desc = gedi.compute(pts=pts0, pcd=_pcd0) # 5000x32\n",
    "\n",
    "    return pcd0_desc, pts0\n",
    "\n",
    "# is scale kept consist from MESH to pcd then goes back? are geometry feature point and dino feature point the same point?\n",
    "def extract_DINO_feature_from_model(model_ckpt, pts):\n",
    "    model = load_checkpoint(model_ckpt)\n",
    "    return model(pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read cached pcd file from ./exp/neus/mixer/meshes/mixer_5000.pcd\n",
      "loaded checkpoint from ./exp/neus/mixer/checkpoints/ckpt_005000.pth\n"
     ]
    }
   ],
   "source": [
    "pcd_path_source = \"./exp/neus/mixer/meshes/mixer_5000.pcd\" \n",
    "pcd_source= load_pointcloud(pcd_path_source)\n",
    "geo_features, sampled_pts = extract_geo_feature(pcd_source) # tensor on cpu, bc some operation dosen't support cuda\n",
    "\n",
    "# move tensor to GPU \n",
    "geo_features = geo_features.to(device)\n",
    "sampled_pts = sampled_pts.to(device)\n",
    "\n",
    "# extract DINO feature\n",
    "ckpt = './exp/neus/mixer/checkpoints/ckpt_005000.pth'\n",
    "DINO_features = extract_DINO_feature_from_model(ckpt,sampled_pts)\n",
    "\n",
    "# combine features\n",
    "features = torch.cat((geo_features,DINO_features),1)\n",
    "# features = DINO_features\n",
    "\n",
    "# pick one point and expand features\n",
    "target_indx = np.random.randint(0,len(sampled_pts)) \n",
    "target_pt = sampled_pts[target_indx]\n",
    "target_feature = features[target_indx].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read cached pcd file from ./exp/neus/owl/meshes/owl.pcd\n",
      "loaded checkpoint from ./exp/neus/owl/checkpoints/ckpt_010000.pth\n"
     ]
    }
   ],
   "source": [
    "# extract features from second pointcloud\n",
    "pcd_path_source2 = \"./exp/neus/owl/meshes/owl.pcd\" \n",
    "pcd_source2= load_pointcloud(pcd_path_source2)\n",
    "geo_features2, sampled_pts2 = extract_geo_feature(pcd_source2) # tensor on cpu, bc some operation dosen't support cuda\n",
    "\n",
    "# move tensor to GPU \n",
    "geo_features2 = geo_features2.to(device)\n",
    "sampled_pts2 = sampled_pts2.to(device)\n",
    "\n",
    "# extract DINO feature\n",
    "ckpt = './exp/neus/owl/checkpoints/ckpt_010000.pth'\n",
    "DINO_features2 = extract_DINO_feature_from_model(ckpt,sampled_pts2)\n",
    "\n",
    "# combine features\n",
    "features2 = torch.cat((geo_features2,DINO_features2),1)\n",
    "# features2 = DINO_features2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 closest pairs (indices and cosine similarities):\n",
      "Pair 1: (features1[7], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 2: (features1[6], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 3: (features1[4], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 4: (features1[5], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 5: (features1[1], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 6: (features1[0], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 7: (features1[2], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 8: (features1[3], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 9: (features1[8], features2[64]), Cosine Similarity: 0.2330734133720398\n",
      "Pair 10: (features1[9], features2[64]), Cosine Similarity: 0.2330734133720398\n"
     ]
    }
   ],
   "source": [
    "features = target_feature.repeat(features2.shape[0],1)\n",
    "# Normalize the features to get cosine similarity\n",
    "features1_norm = F.normalize(features, p=2, dim=1)\n",
    "features2_norm = F.normalize(features2, p=2, dim=1)\n",
    "\n",
    "\n",
    "# Compute cosine similarity between all pairs\n",
    "cosine_sim = torch.mm(features1_norm, features2_norm.t())\n",
    "\n",
    "# Flatten the cosine similarity matrix and get the top 10 indices\n",
    "num_rank = 10\n",
    "cosine_sim_flat = cosine_sim.view(-1)\n",
    "topk_values, topk_indices = torch.topk(cosine_sim_flat, num_rank, largest=True)\n",
    "\n",
    "# Manually convert flat indices to 2D indices\n",
    "n_rows = cosine_sim.size(0)\n",
    "topk_indices_2d = [(idx // n_rows, idx % n_rows) for idx in topk_indices]\n",
    "\n",
    "print(\"Top 10 closest pairs (indices and cosine similarities):\")\n",
    "for i in range(num_rank):\n",
    "    idx1, idx2 = topk_indices_2d[i]\n",
    "    print(f\"Pair {i+1}: (features1[{idx1}], features2[{idx2}]), Cosine Similarity: {topk_values[i].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]\n",
      " [-0.08489986  0.31720576  0.36402828]]\n",
      "[[0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]\n",
      " [0.6743127 1.018662  1.1245183]]\n",
      "[[0, 10], [1, 11], [2, 12], [3, 13], [4, 14], [5, 15], [6, 16], [7, 17], [8, 18], [9, 19]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the corresponding points for the top pairs\n",
    "top_pairs_pts1 = np.array([target_pt.cpu().numpy() for idx1, _ in topk_indices_2d])\n",
    "top_pairs_pts2 = np.array([sampled_pts2[idx2].cpu().numpy()+1.0 for _, idx2 in topk_indices_2d])\n",
    "\n",
    "# Create a new point cloud to hold the combined points for visualization\n",
    "combined_points = np.vstack((sampled_pts.cpu(), sampled_pts2.cpu()+1.0))\n",
    "combined_pcd = o3d.geometry.PointCloud()\n",
    "combined_pcd.points = o3d.utility.Vector3dVector(combined_points)\n",
    "\n",
    "# Create lines connecting the top pairs\n",
    "# lines = [[idx1.cpu().numpy(), (idx2 + len(sampled_pts)).cpu().numpy()] for idx1, idx2 in topk_indices_2d]\n",
    "lines = [[i, i + len(top_pairs_pts1)] for i in range(len(top_pairs_pts1))]\n",
    "\n",
    "# Visualize point clouds with lines between top pairs\n",
    "colors = [[0, 0, 1] for _ in range(len(lines))]  # Blue lines\n",
    "\n",
    "line_set = o3d.geometry.LineSet()\n",
    "line_set.points = o3d.utility.Vector3dVector(np.vstack((top_pairs_pts1, top_pairs_pts2)))\n",
    "line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize the point clouds and the lines\n",
    "o3d.visualization.draw_geometries([combined_pcd, line_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### past results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000 to 5000 code\n",
    "# Normalize the features to get cosine similarity\n",
    "features1_norm = F.normalize(features, p=2, dim=1)\n",
    "features2_norm = F.normalize(features2, p=2, dim=1)\n",
    "\n",
    "# Compute cosine similarity between all pairs\n",
    "cosine_sim = torch.mm(features1_norm, features2_norm.t())\n",
    "\n",
    "# Flatten the cosine similarity matrix and get the top 10 indices\n",
    "num_rank = 3\n",
    "cosine_sim_flat = cosine_sim.view(-1)\n",
    "topk_values, topk_indices = torch.topk(cosine_sim_flat, num_rank, largest=True)\n",
    "\n",
    "# Manually convert flat indices to 2D indices\n",
    "n_rows = cosine_sim.size(0)\n",
    "topk_indices_2d = [(idx // n_rows, idx % n_rows) for idx in topk_indices]\n",
    "\n",
    "print(\"Top 10 closest pairs (indices and cosine similarities):\")\n",
    "for i in range(num_rank):\n",
    "    idx1, idx2 = topk_indices_2d[i]\n",
    "    print(f\"Pair {i+1}: (features1[{idx1}], features2[{idx2}]), Cosine Similarity: {topk_values[i].item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gedi_o3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
